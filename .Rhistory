preProc<-preProcess(training2,method="pca", thresh=0.8)
preProc$rotation
names(preProc)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
training2<-training[grep("^IL",names(training))]
preProc<-preProcess(training2,method="pca", thresh=0.8)
preProc
preProc$rotation
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
head(segmentationOriginal)
class(segmentationOriginal)
datatest<-split(segmentationOriginal,case=Test)
datatest<-split(segmentationOriginal,case="Test")
datatest<-split(segmentationOriginal,segmentationOriginal$case="Test")
datatest<-split(segmentationOriginal,segmentationOriginal$case=Test)
datatest<-split(segmentationOriginal,segmentationOriginal$case=="Test")
split(segmentationOriginal,segmentationOriginal$case)
split(segmentationOriginal,segmentationOriginal$Case)
(split(segmentationOriginal,segmentationOriginal$Case))$Test
dataTest<-(split(segmentationOriginal,segmentationOriginal$Case))$Test
dataTraining<-(split(segmentationOriginal,segmentationOriginal$Case))$Training
head(dataset)
head(segmentationOriginal)
dataTrain<-(split(segmentationOriginal,segmentationOriginal$Case))$Train
rm(datatraining)
rm(dataTraining)
set.seed(125)
modFit<-train(Class ~ ., method="rcart", data=dataTrain)
modFit<-train(Class ~ ., method="rpart", data=dataTrain)
predict(modFit, newdata="TotalIntench2 = 23,000; FiberWidthCh1 = 10; PerimStatusCh1=2")
predict(modFit, newdata="TotalIntench2 = 23,000")
predict(modFit, newdata=dataTest)
qplot(TotalIntench2,FiberWidthCh1,colour=Class,data=dataTraining)
qplot(TotalIntench2,FiberWidthCh1,colour=Class,data=dataTrain)
qplot(Totallntench2,FiberWidthCh1,colour=Class,data=dataTrain)
qplot(TotalIntenCh2,FiberWidthCh1,colour=Class,data=dataTrain)
plot(modFit$finalModel)
plot(modFit$finalModel, uniform=TRUE, main="Class Tree")
text(modFit$finalModel, use.n=TRUE, all=TRUE, cex=.8)
library(rattle)
install.packages("rattle")
library(rattle)
fancyRpartPlot(modFit$finalmodel)
fancyRpartPlot(modFit$finalModel)
install.packages("rpart.plot")
library(rpart.plot)
fancyRpartPlot(modFit$finalModel)
dataTrain[1:3,]
which(colnames(dataTrain)=="TotalIntenCh2")
which(colnames(dataTrain)=="FiberWidthCh1")
which(colnames(dataTrain)=="PerimStatusCh1")
pp<-training[1:10,]
pp<-dataTrain[1:10,]
pp[1,c(103, 50, 85)]=c(23000,10,2)
predict(modFit,pp)
head(pp)
pp[1:10,c(103, 50, 85)]=c(23000,10,2)
head(pp)
x<-23000
y<-10
z<-2
rep<-c(x,x,x,x,x,x,x,x,x,x,y,y,y,y,y,y,y,y,y,y,z,z,z,z,z,z,z,z,z,z,z)
rep
pp[1:10,c(103, 50, 85)]=rep
rep<-c(x,x,x,x,x,x,x,x,x,x,y,y,y,y,y,y,y,y,y,y,z,z,z,z,z,z,z,z,z,z)
pp[1:10,c(103, 50, 85)]=rep
head(pp)
predict(modFit,pp)
x<-50000
y<-10
z<-100
rep<-c(x,x,x,x,x,x,x,x,x,x,y,y,y,y,y,y,y,y,y,y,z,z,z,z,z,z,z,z,z,z)
pp[1:10,c(103, 50, 85)]=rep
predict(modFit,pp)
x<-57000
y<-8
z<-100
rep<-c(x,x,x,x,x,x,x,x,x,x,y,y,y,y,y,y,y,y,y,y,z,z,z,z,z,z,z,z,z,z)
pp[1:10,c(103, 50, 85)]=rep
predict(modFit,pp)
which(colnames(dataTrain)=="VarIntenCh4")
x<-8
y<-100
z<-2
rep<-c(x,x,x,x,x,x,x,x,x,x,y,y,y,y,y,y,y,y,y,y,z,z,z,z,z,z,z,z,z,z)
pp[1:10,c(50, 85, 112)]=rep
predict(modFit,pp)
head(pp)
which(colnames(dataTrain)=="VarIntenCh4")
pp[1:10,c(50, 112, 85)]=rep
predict(modFit,pp)
head(pp)
setwd("~/Desktop/Johns Hopkins University Data Science/7.- Practical Machine Learning")
demo()
library(caret)
library(randomForest)
set.seed(123)
train<-read.csv("pml-training.csv")
test<-read.csv("pml-testing.csv")
train<-train[,!sapply(train, function(x) any(is.na(x)))]
train<-train[,!sapply(train, function(x) any(x==""))]
test<-test[,!sapply(test, function(x) any(is.na(x)))]
test<-test[,!sapply(test, function(x) any(x==""))]
inTrain<-createDataPartition(y=train$classe,p=0.6,list=FALSE)
training<-train[inTrain,]
testing<-train[-inTrain,]
modFit <- train(classe~roll_belt+pitch_belt+yaw_belt+pitch_forearm+magnet_dumbbell_z+roll_arm, method="rf", data=training, verbose=FALSE)
confusionMatrix(testing,predict(modFit,testing))
predict(modFit,testing)
confusionMatrix(testing$classe,predict(modFit,testing))
predict(modFit,test)
modFit$Varimp
modFit$VarImp
modFit$varImp
modFit(summary)
modFit
summary(modFit)
modFit$varImp
modFit$VarImp
modFit$Var
modFit$VarImp
varImp(Ã‡modfit)
varImp(modfit)
varImp(modFit)
plot(varImp(modFit))
modFit <- train(classe~., method="rf", data=training, verbose=FALSE)
plot(varImp(modFit))
plot(varImp(modFit(1:5)))
plot(varImp(modFit(1:5)):1:5)
plot(varImp(modFit[1:5]))
plot(varImp(modFit))
plot(varImp(modFit)[1:5])
plot(varImp(modFit)[1:5,])
plot(varImp(modFit)[,1:5])
plot(varImp(modFit)[,1])
plot(varImp(modFit)[1])
plot(varImp(modFit))
plot(varImp(modFit)$1)
plot(varImp(modFit)[1])
plot(varImp(modFit)[,1])
plot(varImp(modFit)[1,])
varImp(modFit)
class(varImp(modFit))
class(varImp(modFit))[1]
class(varImp(modFit))[2]
class(varImp(modFit))[3]
class(varImp(modFit))[1,1]
class(varImp(modFit))[1,]
class(varImp(modFit))[1]
predict(modFit,test)
test
predict(modFit,test)
predict(modFit,testing)
colnames(training)
names(training)
all.equal(names(test),names(train))
names(test)-names(train)
names(test[,-60])-names(train)
names(test[-60])
all.equal(names(test)[-60],names(train)[-60])
head(test)
test<-test[-1:7]
test<-test[-1:7,]
test<-test[!1:7]
test
test<-read.csv("pml-testing.csv")
test<-test[,!sapply(test, function(x) any(is.na(x)))]
test<-test[,!sapply(test, function(x) any(x==""))]
test[-1]
test[-1:7]
test[-(1:7)]
test<-test[-(1:7)]
testing<-testing[-(1:7)]
train<-train[-(1:7)]
training<-training[-(1:7)]
modFit <- train(classe~., method="rf", data=training, verbose=FALSE)
modFit <- train(classe~roll_belt+pitch_belt+yaw_belt+pitch_forearm+magnet_dumbbell_z+roll_arm, method="rf", data=training, verbose=TRUE)
varImpo(modFit)
varImp(modFit)
plot(varImp(modFit))
predict(modFit,test)
confusionMatrix(testing$clsee,predict(modFit,testing))
confusionMatrix(testing$classe,predict(modFit,testing))
modFit <- train(classe~., method="rf", data=training, verbose=TRUE)
predict(modFit,test)
modFit2 <- train(classe~., method="rpart", data=training, verbose=FALSE)
modFit2 <- train(classe~., method="rpart", data=training)
predict(modFit2,test)
modfit2
modFit2
print(modFit2$finalModel)
set.sed(123)
set.seed(123)
modFit2 <- train(classe~., method="rpart", data=training)
predict(modFit2,test)
confusionMatrix(testing$clsee,predict(modFit2,testing))
confusionMatrix(testing$classe,predict(modFit2,testing))
modFit3 <- train(classe~., method="cv", data=training)
modFit3 <- train(classe~., method="glm", data=training)
modFit3 <- train(classe~., method="glm", data=testing)
warninigs()
warnings()
modFit3 <- train(classe~., method="glm", data=training)
modFit3 <- train(classe~., method="lm", data=training)
modFit3 <- train(classe~., method="glm", data=training)
modFit3 <- train(classe~., method="nnet", data=training)
modFit3
predict(modFit3,test)
confusionMatrix(testing$classe,predict(modFit3,testing))
confusionMatrix(testing$classe,predict(modFit1,testing))
confusionMatrix(testing$classe,predict(modFit,testing))
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
head(vowe)
head(vowel.test)
vowel.test$y
vowel.test$y<-as.factor(vowel.test$y)
vowel.train$y<-as.factor(vowel.train$y)
set.seed(33833)
mod1z-train(y~.,data=vowel.train)
mod1<-train(y~.,data=vowel.train)
mod1<-train(y~.,data=vowel.train,method="rf")
mod2<-train(y~.,data=vowel.train,method="gbm")
mod1%finalModel
mod1$finalModel
1.0,265
1-.265
1-.9881
mod1
mod2
summary)mod1
summary(mod1)
confusionMatrix(vowel.train,predict(mod1,vowel.test))
confusionMatrix(vowel.test,predict(mod1,vowel.test))
predict(mod1,vowel.test)
confusionMatrix(vowel.test,predict(mod2,vowel.test))
class(vowel.test)
confusionMatrix(vowel.test$y,predict(mod2,vowel.test))
1-.4619
confusionMatrix(vowel.test$y,predict(mod2,vowel.test))
confusionMatrix(vowel.test$y,predict(mod1,vowel.test))
confusionMatrix(vowel.test$y,predict(mod2,vowel.test))
sum((predict(modelRF, vowel.test) == vowel.test$y)*1) / length(vowel.test$y)
sum((predict(model1, vowel.test) == vowel.test$y)*1) / length(vowel.test$y)
sum((predict(mod1, vowel.test) == vowel.test$y)*1) / length(vowel.test$y)
sum((predict(mod2, vowel.test) == vowel.test$y)*1) / length(vowel.test$y)
sum((predict(mod1, vowel.test) == predict(mod2, vowel.test))*1) / length(vowel.test$y)
library(caret)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
modelRF <- train(y ~ ., data = vowel.train, method = "rf")
modelGBM <- train(y ~ ., data = vowel.train, method = "gbm", verbose = F)
sum((predict(modelRF, vowel.test) == vowel.test$y)*1) / length(vowel.test$y)
sum((predict(modelGBM, vowel.test) == vowel.test$y)*1) / length(vowel.test$y)
sum((predict(modelRF, vowel.test) == predict(modelGBM, vowel.test))*1) / length(vowel.test$y)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.test$y<-as.factor(vowel.test$y)
vowel.train$y<-as.factor(vowel.train$y)
mod1<-train(y~.,data=vowel.train,method="rf")
mod2<-train(y~.,data=vowel.train,method="gbm")
confusionMatrix(vowel.test$y,predict(mod1,vowel.test))
confusionMatrix(vowel.test$y,predict(mod2,vowel.test))
sum((predict(mod1, vowel.test) == vowel.test$y)*1) / length(vowel.test$y)
sum((predict(mod2, vowel.test) == vowel.test$y)*1) / length(vowel.test$y)
sum((predict(mod1, vowel.test) == predict(mod1, vowel.test))*1) / length(vowel.test$y)
sum((predict(mod1, vowel.test) == predict(mod2, vowel.test))*1) / length(vowel.test$y)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.test$y<-as.factor(vowel.test$y)
vowel.train$y<-as.factor(vowel.train$y)
set.seed(33833)
mod1<-train(y~.,data=vowel.train,method="rf")
mod2<-train(y~.,data=vowel.train,method="gbm")
confusionMatrix(vowel.test$y,predict(mod1,vowel.test))
confusionMatrix(vowel.test$y,predict(mod2,vowel.test))
sum((predict(mod1, vowel.test) == predict(mod2, vowel.test))*1) / length(vowel.test$y)
wovel.test$y
vowel.test$y
predict(mod1,vowel.test)
vowel.test$y-predict(mod1,vowel.test$y)
vowel.test$y-predict(mod1,vowel.test)
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(62433)
head(training)
mod1<-train(diagnosis~.,method="rf",verbose=FALSE)
mod1<-train(diagnosis~.,method="rf",data=training,verbose=FALSE)
mod2<-train(diagnosis~.,method="gbm",data=training,verbose=FALSE)
mod3<-train(diagnosis~.,method="lda",data=training,verbose=FALSE)
confusionMatrix(testing$dignosis,predict(mod1,testing))
confusionMatrix(testing$diagnosis,predict(mod1,testing))
confusionMatrix(testing$diagnosis,predict(mod2,testing))
confusionMatrix(testing$diagnosis,predict(mod3,testing))
A = max(mod1$results$Accuracy)
B = max(mod2$results$Accuracy)
C = max(mod3$results$Accuracy)
mod1$results
A*B*C+(1-A)*B*C+A*(1-B)*C+A*B*(1-C)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(233)
head(testing)
mod<-train(CompressiveStrength~.,method="lasso",data=training)
mod
mod$finalmodel
mod$finalModel
head(testing)
plot(mod$finalModel, xvar = "penalty", use.color = T)
library(lubridate)  # For year() function below
dat = read.csv("~/Desktop/gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
library(lubridate)  # For year() function below
dat = read.csv("~/Desktop/gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
library(lubridate)  # For year() function below
install.packages("lubridate")
library(lubridate)  # For year() function below
dat = read.csv("~/Desktop/gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
model = bats(tstrain)
require(caret)
model = bats(tstrain)
library(forecast)
install.packages("forecast")
library(forecast)
model = bats(tstrain)
fore = forecast(model, 235)
fore
plot(fore)
lo = fore$lower[,2]
lo
hi = fore$upper[,2]
round(sum(testing[,3] <= hi & testing[,3] >= lo) / length(lo),2)*100
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(325)
model = svm(CompressiveStrength ~ ., data = concrete)
library(e1071)
model = svm(CompressiveStrength ~ ., data = concrete)
model
sqrt(sum((predict(model, testing) - testing$CompressiveStrength)^2))
sqrt(sum((predict(model, testing) - testing$CompressiveStrength)^2))
model = svm(CompressiveStrength ~ ., data = concrete)
sqrt(sum((predict(model, testing) - testing$CompressiveStrength)^2))
set.seed(325)
model = svm(CompressiveStrength ~ ., data = concrete)
sqrt(sum((predict(model, testing) - testing$CompressiveStrength)^2))
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(325)
model = svm(CompressiveStrength ~ ., data = training)
sqrt(sum((predict(model, testing) - testing$CompressiveStrength)^2))
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(62433)
mod1<-train(diagnosis~.,data=training, model="rf",verbose=FALSE)
mod2<-train(diagnosis~.,data=training, model="gbm",verbose=FALSE)
mod3<-train(diagnosis~.,data=training, model="lda",verbose=FALSE)
pred1 <- predict(mod1, newdata = testing)
pred2 <- predict(mod2, newdata = testing)
pred3 <- predict(mod3, newdata = testing)
DF_combined <- data.frame(pred1, pred2, pred3, diagnosis = testing$diagnosis)
DF_combined
mod4 <- train(diagnosis ~ ., data = DF_combined, method = "rf")
confusionMatrix(predict(mod4,testing), testing$diagnosis)
confusionMatrix(predict(mod4,testing), testing$diagnosis)$overall
confusionMatrix(predict(mod1,testing), testing$diagnosis)$overall
confusionMatrix(predict(mod2,testing), testing$diagnosis)$overall
confusionMatrix(predict(mod3,testing), testing$diagnosis)$overall
confusionMatrix(predict(mod4,testing), testing$diagnosis)$overall
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(325)
library(e1071)
model = svm(CompressiveStrength ~ ., data = concrete)
sqrt(sum((predict(model, testing) - testing$CompressiveStrength)^2))
(sum((predict(model, testing) - testing$CompressiveStrength)^2))
sqrt(sum((predict(model, testing) - testing$CompressiveStrength)^2))
setwd("~/Desktop/Johns Hopkins University Data Science/7.- Practical Machine Learning")
library(caret)
library(randomForest)
set.seed(123)
train<-read.csv("pml-training.csv")
test<-read.csv("pml-testing.csv")
head(test)
train<-train[,!sapply(train, function(x) any(is.na(x)))]
train<-train[,!sapply(train, function(x) any(x==""))]
test<-test[,!sapply(test, function(x) any(is.na(x)))]
test<-test[,!sapply(test, function(x) any(x==""))]
names(test)
train<-read.csv("pml-training.csv")
train<-read.csv("pml-training.csv")
train<-read.csv("pml-training.csv")
train<-train[,!sapply(train, function(x) any(x==""))]
rm(test)
rm(train)
library(caret)
library(randomForest)
set.seed(123)
train<-read.csv("pml-training.csv")
test<-read.csv("pml-testing.csv")
train<-train[,!sapply(train, function(x) any(is.na(x)))]
train<-train[,!sapply(train, function(x) any(x==""))]
test<-test[,!sapply(test, function(x) any(is.na(x)))]
test<-test[,!sapply(test, function(x) any(x==""))]
inTrain<-createDataPartition(y=train$classe,p=0.75,list=FALSE)
training<-train[inTrain,]
testing<-train[-inTrain,]
modFit <- train(factor(classe)~., method="rf", data=training, verbose=FALSE)
testPred<-predict(modFit,test)
testPred
set.seed(1234)
modFit <- train(factor(classe)~., method="rf", data=training, verbose=FALSE,importance=TRUE)
testPred<-predict(modFit,test)
testPred
head(train)
head(test)
testPred<-predict(modFit,newdata=test)
testPred
modfit
modFit$finalModel
print(modFit)
modFit
predict(modFit,test)
modFit <- train(training$classe ~., method="rf", data=training, verbose=FALSE)
testPred<-predict(modFit,newdata=test)
testPred
Test<-read.csv("pml-testing.csv")
testPred<-predict(modFit,newdata=Test)
predict(modFit,newdata=Test)
head(testing)
head(testing[1:8,])
head(Test[1:8,])
head(Test[,1:8])
head(Test[,1:7])
head(train[,1:7])
head(!train[,1:7])
!train[,1:7]
head(train[-1:7])
head(train[-1])
head(train[-2])
head(train[-(1:7)])
library(caret)
library(randomForest)
set.seed(12345)
Train<-read.csv("pml-training.csv")
Test<-read.csv("pml-testing.csv")
Train<-Train[-(1:7)]
Test<-Test[-(1:7)]
Train<-Train[,!sapply(Train, function(x) any(is.na(x)))]
Train<-Train[,!sapply(Train, function(x) any(x==""))]
Test<-Test[,!sapply(Test, function(x) any(is.na(x)))]
Test<-Test[,!sapply(Test, function(x) any(x==""))]
inTrain<-createDataPartition(y=Train$classe,p=0.75,list=FALSE)
Training<-Train[inTrain,]
Testing<-Train[-inTrain,]
modFit <- train(Training$classe~., method="rf", data=Training, verbose=FALSE)
modFit$finalModel
modFit<-train(Training$classe~., method="rf", data=Training, verbose=TRUE)
